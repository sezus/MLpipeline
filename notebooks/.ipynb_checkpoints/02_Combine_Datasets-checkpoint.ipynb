{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..') \n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from src.intermediate.Combine_Datasets import select_WT_fault_count_bigger_than_threshold,concat_data_set\n",
    "from src.utils.utils_p import save_dataset_pickle,download_pickle,load_config\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #yaml file Load path:\n",
    "    import pathlib\n",
    "    p=pathlib.Path().absolute()\n",
    "    par=p.parent / 'src' \n",
    "    CONFIG_PATH =str(par)\n",
    "\n",
    "    #Load project config from yaml file:\n",
    "    config = load_config(CONFIG_PATH,'importcsv.yaml')\n",
    "    \n",
    "    #Dataset Tags:\n",
    "    Upload_tag=config[\"Upload_list_all\"][\"Upload_Tags\"]\n",
    "\n",
    "    #Select Tag to Upload\n",
    "    TagName=Upload_tag[0]\n",
    "\n",
    "    #Dataset Information:\n",
    "    tag=config[\"Upload_list_all\"][TagName]\n",
    "    \n",
    "    #For Combining multiple dataset as dataframe a identification column needed:\n",
    "    Tag_Column=config[\"Upload_list_all\"][\"Tag_Column\"]\n",
    "    \n",
    "    #Raw Data path:\n",
    "    raw_path=config[\"Upload_list_all\"]['Parent_path']+\"data/01_raw/\" \n",
    "   \n",
    "    #Intermediate Preprocessing path:\n",
    "    intermediate_path=config[\"Upload_list_all\"]['Parent_path']+\"/data/02_intermediate/\" \n",
    "    \n",
    "    #CombinedDataset path:\n",
    "    combined_path=config[\"Upload_list_all\"]['Parent_path']+\"/data/03_combinedDatasets/\" \n",
    "    \n",
    "    #Target Prediction Column\n",
    "    Target_Column=config[\"Upload_list_all\"][\"Target_Column\"]\n",
    "    \n",
    "    #1.Create A List of Datasets from Each Tag:\n",
    "    Features_List=[]\n",
    "    Labels_List=[]\n",
    "    for tag in Upload_tag:\n",
    "        #Download pickle files\n",
    "        tag_f=download_pickle(intermediate_path,'Features'+tag)\n",
    "        tag_i=download_pickle(intermediate_path,'Labels'+tag)\n",
    "        #Add identifier tag\n",
    "        tag_f[Tag_Column]=tag\n",
    "        tag_i[Tag_Column]=tag\n",
    "        #Attach all datasets to List\n",
    "        Features_List.append(tag_f)\n",
    "        Labels_List.append(tag_i)     \n",
    "\n",
    "    #2.Create DataFrames from List:    \n",
    "    Features_df=concat_data_set(Features_List)\n",
    "    Labels_df=concat_data_set(Labels_List)\n",
    "    \n",
    "    #3.Optional: Only Select Datasets has enough Target Examples:   \n",
    "    selectedTags=select_WT_fault_count_bigger_than_threshold(Labels_df,Tag_Column,Target_Column,100)  \n",
    "    #Filter Dataframes according to SelectedTags:\n",
    "    Features_selected=Features_df[Features_df[Tag_Column].isin(selectedTags)]\n",
    "    Labels_df=Labels_df[Labels_df[Tag_Column].isin(selectedTags)]\n",
    "    \n",
    "    #Drop unnecessary Labels and select the Target_Column and Tag_Column\n",
    "    Labels_selected=Labels_df[[Target_Column,Tag_Column]]\n",
    "    \n",
    "    #Filter DataLists according to SelectedTags:\n",
    "    Features_selected_list=[]\n",
    "    Labels_selected_list=[]\n",
    "    \n",
    "    for i in Features_List:\n",
    "        select=i[i.TURBINE_NUMBER.isin(selectedTags)].copy()\n",
    "        #select=select[select.columns[1:-2]]\n",
    "        Features_selected_list.append(select)\n",
    "\n",
    "    for i in Labels_List:\n",
    "        i_df=i[i.TURBINE_NUMBER.isin(selectedTags)].copy()\n",
    "        select=i_df[[Target_Column]]\n",
    "        Labels_selected_list.append(select)\n",
    "        \n",
    "    #Save Feature,Label DataFrames:    \n",
    "    save_dataset_pickle(combined_path,'Features_df',Features_selected)\n",
    "    save_dataset_pickle(combined_path,'Labels_df',Labels_selected)    \n",
    "    save_dataset_pickle(combined_path,'Features_List',Features_selected_list)\n",
    "    save_dataset_pickle(combined_path,'Labels_List',Labels_selected_list) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Brake system', 'Brake systemEv', 'Brake systemEv_multiclass',\n",
       "       'Components', 'Components_multiclass', 'Converter', 'ConverterEv',\n",
       "       'ConverterEv_multiclass', 'Events', 'Events_0', 'Events_EVENT_001',\n",
       "       'Events_EVENT_014', 'Events_EVENT_016', 'Events_EVENT_035',\n",
       "       'Events_EVENT_045', 'Events_EVENT_051', 'Events_EVENT_052',\n",
       "       'Events_EVENT_053', 'Events_EVENT_054', 'Events_EVENT_062',\n",
       "       'Events_EVENT_063', 'Events_EVENT_071', 'Events_EVENT_077',\n",
       "       'Events_EVENT_097', 'Events_EVENT_102', 'Events_EVENT_106',\n",
       "       'Events_EVENT_113', 'Events_EVENT_121', 'Events_EVENT_124',\n",
       "       'Events_EVENT_134', 'Events_EVENT_137', 'Events_EVENT_141',\n",
       "       'Events_EVENT_142', 'Events_EVENT_144', 'Events_EVENT_149',\n",
       "       'Events_EVENT_150', 'Events_EVENT_157', 'Events_EVENT_163',\n",
       "       'Events_EVENT_208', 'Events_EVENT_212', 'Events_EVENT_214',\n",
       "       'Events_EVENT_222', 'Events_EVENT_247', 'Events_EVENT_264',\n",
       "       'Events_EVENT_275', 'Events_EVENT_276', 'Events_EVENT_280',\n",
       "       'Events_EVENT_327', 'Events_EVENT_336', 'Events_EVENT_339',\n",
       "       'Events_EVENT_353', 'Events_EVENT_358', 'Events_EVENT_422',\n",
       "       'Events_EVENT_426', 'Events_multiclass', 'Gearbox', 'GearboxEv',\n",
       "       'GearboxEv_multiclass', 'Generator', 'GeneratorEv',\n",
       "       'GeneratorEv_multiclass', 'Period', 'Pitch system', 'Pitch systemEv',\n",
       "       'Pitch systemEv_multiclass', 'Rotor', 'RotorEv', 'RotorEv_multiclass',\n",
       "       'Safety chain system', 'Safety chain systemEv',\n",
       "       'Safety chain systemEv_multiclass', 'TURBINE_NUMBER',\n",
       "       'Top Control Cabinet', 'Top Control CabinetEv',\n",
       "       'Top Control CabinetEv_multiclass', 'Turbine control system',\n",
       "       'Turbine control systemEv', 'Turbine control systemEv_multiclass',\n",
       "       'Ultrasonic Anomemeter', 'Ultrasonic AnomemeterEv',\n",
       "       'Ultrasonic AnomemeterEv_multiclass', 'Yaw system', 'Yaw systemEv',\n",
       "       'Yaw systemEv_multiclass'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Labels_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
