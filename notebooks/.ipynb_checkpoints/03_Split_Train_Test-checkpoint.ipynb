{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_list[i] (45023, 31)\n",
      "y_list[i] (45023, 1)\n",
      "X_list[i] (0, 31)\n",
      "y_list[i] (0, 1)\n",
      "X_list[i] (0, 31)\n",
      "y_list[i] (0, 1)\n",
      "X_list[i] (46559, 31)\n",
      "y_list[i] (46559, 1)\n",
      "X_list[i] (0, 31)\n",
      "y_list[i] (0, 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..') \n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from src.processing.Split_Train_Test import convert_dataframe_to_list,drop_columns_from_List_Dataframes,traintestsplit\n",
    "from src.utils.utils_p import save_dataset_pickle,download_pickle,load_config\n",
    "import pathlib\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #yaml file Load path:\n",
    "    p=pathlib.Path().absolute()\n",
    "    par=p.parent / 'src' \n",
    "    CONFIG_PATH =str(par)\n",
    "    \n",
    "    #Load project config from yaml file:    \n",
    "    config = load_config(CONFIG_PATH,'importcsv.yaml')\n",
    "    \n",
    "    # Intermediate file paths for combined datasets\n",
    "    intermediate_path=config[\"Upload_list_all\"]['Parent_path']+\"data/02_intermediate/\" \n",
    "    \n",
    "    #CombinedDataset path:\n",
    "    combined_path=config[\"Upload_list_all\"]['Parent_path']+\"/data/03_combinedDatasets/\" \n",
    "    \n",
    "    # Process file path to save Splited Train, Test datasets\n",
    "    processed_path=config[\"Upload_list_all\"]['Parent_path']+\"data/04_processed/\"\n",
    "\n",
    "    #\n",
    "    Target_Column=config[\"Upload_list_all\"][\"Target_Column\"]\n",
    "    \n",
    "    #Download Combined & Selected Datasets as List and DataFrames\n",
    "    #DataFrames: Features_df,Labels_df \n",
    "    Features_df=download_pickle(combined_path,'Features_df')\n",
    "    Labels_df=download_pickle(combined_path,'Labels_df')\n",
    "    #Lists: Features_List,Labels_List\n",
    "    Features_List=download_pickle(combined_path,'Features_List')\n",
    "    Labels_List=download_pickle(combined_path,'Labels_List') \n",
    "\n",
    "    #DataFrame split train test:\n",
    "    X_trains, X_test, y_trains, y_test = train_test_split(Features_df[Features_df.columns[1:-2]],Labels_df[Target_Column],test_size=0.25,random_state=30,shuffle=True)\n",
    "\n",
    "    #List split train test:    \n",
    "    #Drop unnecessary Columns:\n",
    "    Features_List=drop_columns_from_List_Dataframes(Features_List,['Period','TURBINE_NUMBER','Events_binary'])\n",
    "    X_trains_list,X_tests_list,y_trains_list,y_tests_list = traintestsplit(Features_List,Labels_List,0.2)\n",
    "    \n",
    "    #Save List and DataFrame train,test sets as :\n",
    "    #Dataframe: X_trains, X_test, y_trains,y_test\n",
    "    #Save Feature,Label DataFrames:    \n",
    "    save_dataset_pickle(processed_path,'X_trains',X_trains)\n",
    "    save_dataset_pickle(processed_path,'X_test',X_test)    \n",
    "    save_dataset_pickle(processed_path,'y_trains',y_trains)\n",
    "    save_dataset_pickle(processed_path,'y_test',y_test) \n",
    "\n",
    "    #List: X_trains_list,X_tests_list,y_trains_list,y_tests_list        \n",
    "    save_dataset_pickle(processed_path,'X_trains_list',X_trains_list)\n",
    "    save_dataset_pickle(processed_path,'X_tests_list',X_tests_list)    \n",
    "    save_dataset_pickle(processed_path,'y_trains_list',y_trains_list)\n",
    "    save_dataset_pickle(processed_path,'y_tests_list',y_tests_list) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
