{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score, make_scorer\n",
    "\n",
    "#türbin datalarını birleştirmek üzere kullanılır. \n",
    "def concat_data_set(datalist):\n",
    "    for data in datalist:\n",
    "        concatdata = pd.concat(datalist,ignore_index=True)\n",
    "    return concatdata\n",
    "\n",
    "# Function to load yaml configuration file\n",
    "def load_config(config_name):\n",
    "    with open(os.path.join(CONFIG_PATH,  config_name), 'r', encoding='utf8') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    return config\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    CONFIG_PATH = \".\"\n",
    "    config = load_config('importcsv.yaml')\n",
    "    Upload_tag=config[\"Upload_list_all\"][\"Upload_Tags\"]\n",
    "    tag=config[\"Upload_list_all\"][Upload_tag[0]]\n",
    "    raw_path=config[\"Upload_list_all\"]['Parent_path']+\"data/01_raw/\" \n",
    "    upload_path=raw_path+\"uploaded/\" \n",
    "    intermediate_path=config[\"Upload_list_all\"]['Parent_path']+\"/data/02_intermediate/\" \n",
    "    combined_path=intermediate_path + \"CombinedDatasets/\"\n",
    "    processed_path=config[\"Upload_list_all\"]['Parent_path']+\"data/03_processed/\"\n",
    "    RF_params=config[\"Upload_list_all\"][\"Model_Parameters\"][\"RandomForest\"]\n",
    "\n",
    "    with open(processed_path +'selectedfeatures', 'rb') as config_dictionary_file:\n",
    "        selectedfeatures = pickle.load(config_dictionary_file)\n",
    "    with open(processed_path +'X_trains', 'rb') as config_file:\n",
    "        X_trains = pickle.load(config_file)\n",
    "    with open(processed_path +'X_test', 'rb') as config_file:\n",
    "        X_tests = pickle.load(config_file)\n",
    "    with open(processed_path +'y_trains', 'rb') as config_file:\n",
    "        y_trains = pickle.load(config_file)\n",
    "    with open(processed_path +'y_test', 'rb') as config_file:\n",
    "        y_tests = pickle.load(config_file)    \n",
    "\n",
    "    with open(processed_path +'X_trains_list', 'rb') as config_file:\n",
    "        X_trains_list = pickle.load(config_file)\n",
    "    with open(processed_path +'X_tests_list', 'rb') as config_file:\n",
    "        X_tests_list = pickle.load(config_file)\n",
    "    with open(processed_path +'y_trains_list', 'rb') as config_file:\n",
    "        y_trains_list = pickle.load(config_file)\n",
    "    with open(processed_path +'y_tests_list', 'rb') as config_file:\n",
    "        y_tests_list = pickle.load(config_file)\n",
    "\n",
    "    ## List input\n",
    "    X_train = concat_data_set(X_trains_list)\n",
    "    y_train = concat_data_set(y_trains_list)\n",
    "    X_test = concat_data_set(X_tests_list)\n",
    "    y_test = concat_data_set(y_tests_list)\n",
    "\n",
    "    # DataFrame input\n",
    "\n",
    "    #parameters = {\n",
    "    #'max_depth':range(5,15,1),\n",
    "    #'min_impurity_split':[1e-1,1e-2,1e-3,1e-4,1e-5]\n",
    "    #}\n",
    "    parameters = {\n",
    "    'max_depth':RF_params[\"max_depth\"],\n",
    "    'min_impurity_split':RF_params[\"min_impurity_split\"]\n",
    "    }\n",
    "    \n",
    "    bests_RFC = {}\n",
    "\n",
    "    combined_X_test = concat_data_set(X_tests_list)\n",
    "    combined_y_test = concat_data_set(y_tests_list)\n",
    "    method='f_classif'\n",
    "    classifier = RandomForestClassifier(n_jobs = 10, random_state = 23)\n",
    "    gridsearcher = GridSearchCV(classifier, parameters, cv=10, scoring=make_scorer(f1_score))\n",
    "    gridsearcher.fit(X_train[selectedfeatures],y_train)\n",
    "    f1_tests = []\n",
    "    for i in range(len(X_tests_list)):\n",
    "        y_pred = gridsearcher.predict(X_tests_list[i][selectedfeatures])\n",
    "        f1_test = f1_score(y_tests_list[i],y_pred)\n",
    "        f1_tests.append(f1_test)\n",
    "    y_pred = gridsearcher.predict(X_test[selectedfeatures])\n",
    "    f1_test = f1_score(y_test,y_pred)\n",
    "    bests_RFC = {}\n",
    "    bests_RFC['best_parameters'] = gridsearcher.best_params_\n",
    "    bests_RFC['f1_test_seperated'] = f1_tests\n",
    "    bests_RFC['f1_test_combined'] = f1_test\n",
    "    bests_RFC['cv_results'] = gridsearcher.cv_results_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
