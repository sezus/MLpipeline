{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "#Convert dataframe to list according to reference column unique values\n",
    "def convert_dataframe_to_list(df,refcolumn):\n",
    "    X_list=[]\n",
    "    for i in df[refcolumn].unique():\n",
    "        ref_df=df[df[refcolumn]==i].copy()\n",
    "        ref_df.drop(refcolumn,axis='columns')\n",
    "        X_list.append(ref_df) \n",
    "    return X_list\n",
    "#türbin datalarını birleştirmek üzere kullanılır. \n",
    "\n",
    "#list içerisinde verilmiş birden fazla feature ve label set'ini verilen test oranına göre ayrıştırır.\n",
    "\n",
    "def traintestsplit(X_list, y_list, test_size_val):\n",
    "    X_trains=[]\n",
    "    X_tests=[]\n",
    "    y_trains=[]\n",
    "    y_tests=[]\n",
    "    for i in range(len(X_list)):\n",
    "        X_train,X_test,y_train,y_test = train_test_split(X_list[i],y_list[i],test_size=test_size_val,shuffle=True)\n",
    "        X_trains.append(X_train)\n",
    "        X_tests.append(X_test)\n",
    "        y_trains.append(y_train)\n",
    "        y_tests.append(y_test)\n",
    "    return X_trains,X_tests,y_trains,y_tests\n",
    "\n",
    "\n",
    "# Function to load yaml configuration file\n",
    "def load_config(config_name):\n",
    "    with open(os.path.join(CONFIG_PATH,  config_name), 'r', encoding='utf8') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    return config\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    CONFIG_PATH = \".\"\n",
    "    config = load_config('importcsv.yaml')\n",
    "    Upload_tag=config[\"Upload_list_all\"][\"Upload_Tags\"]\n",
    "    tag=config[\"Upload_list_all\"][Upload_tag[0]]\n",
    "    raw_path=config[\"Upload_list_all\"]['Parent_path']+\"data/01_raw/\" \n",
    "    upload_path=raw_path+\"uploaded/\" \n",
    "    intermediate_path=config[\"Upload_list_all\"]['Parent_path']+\"data/02_intermediate/\" \n",
    "    combined_path=intermediate_path + \"CombinedDatasets/\"\n",
    "    processed_path=config[\"Upload_list_all\"]['Parent_path']+\"data/03_processed/\"\n",
    "    Target_Label=config[\"Upload_list_all\"][\"Target_Column\"]\n",
    "\n",
    "    with open(combined_path+'Features_df', 'rb') as config_file:\n",
    "        Features_df= pickle.load(config_file)\n",
    "    with open(combined_path +'Labels_df', 'rb') as config_file:\n",
    "        Labels_df= pickle.load(config_file)\n",
    "    with open(combined_path+'Features_List', 'rb') as config_file:\n",
    "        Features_List= pickle.load(config_file)\n",
    "    with open(combined_path +'Labels_List', 'rb') as config_file:\n",
    "        Labels_List= pickle.load(config_file)\n",
    "    \n",
    "    #Labels_df=Labels.set_index(['Period']).copy()\n",
    "    #Features_df=Features.set_index(['Period']).copy()  \n",
    "    #Features_df['COMPONENTS_Pitch system']=Labels_df['COMPONENTS_Pitch system']\n",
    "    #Features_df=Features_df.reset_index()\n",
    "    #Labels_df=Labels_df.reset_index()\n",
    "    \n",
    "    #Whole Data DataFrame split test,train,validation set:\n",
    "    #print(Features_df.columns)\n",
    "    ##*****duzeltilecek Features_df'de gereksiz labellar kalmis onceki adimda duzelt!\n",
    "    X_trains, X_test, y_trains, y_test = train_test_split(Features_df[Features_df.columns[1:-2]],Labels_df[Target_Label],test_size=0.25,random_state=30,shuffle=True)\n",
    "    \n",
    "    #List split train test\n",
    "    X_trains_list,X_tests_list,y_trains_list,y_tests_list = traintestsplit(Features_List,Labels_List,0.2)\n",
    "\n",
    "    with open(processed_path +'X_trains', 'wb') as config_file:\n",
    "        pickle.dump(X_trains, config_file)\n",
    "    with open(processed_path +'X_test', 'wb') as config_file:\n",
    "        pickle.dump(X_test, config_file)\n",
    "    with open(processed_path +'y_trains', 'wb') as config_file:\n",
    "        pickle.dump(y_trains, config_file)\n",
    "    with open(processed_path +'y_test', 'wb') as config_file:\n",
    "        pickle.dump(y_test, config_file)\n",
    "   \n",
    "    with open(processed_path +'X_trains_list', 'wb') as config_file:\n",
    "        pickle.dump(X_trains_list, config_file)\n",
    "    with open(processed_path +'X_tests_list', 'wb') as config_file:\n",
    "        pickle.dump(X_tests_list, config_file)\n",
    "    with open(processed_path +'y_trains_list', 'wb') as config_file:\n",
    "        pickle.dump(y_trains_list, config_file)\n",
    "    with open(processed_path +'y_tests_list', 'wb') as config_file:\n",
    "        pickle.dump(y_tests_list, config_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
